{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# min_df默认为1，忽略出现词频小于1的词==不忽略任何词\n",
    "# stop_words = 'english' 即忽略英语中高频但是没意义的词如“a、most、about“等\n",
    "vectorizer = CountVectorizer(min_df=1,stop_words='english')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n       [1, 0],\n       [0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = [\"what the fuck\",\"what is the hard disk\"]\n",
    "x = vectorizer.fit_transform(content)\n",
    "x.toarray().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['disk', 'fuck', 'hard']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "TOY_DIR = Path(r'building machine learning systems with python/data/toy')\n",
    "TOY_DIR.is_dir()                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = []\n",
    "for fn in TOY_DIR.iterdir():\n",
    "    with open(fn, 'r') as f:\n",
    "        posts.append(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 18)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = vectorizer.fit_transform(posts)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "new_post = \"imaging databases\"\n",
    "new_post_vec = vectorizer.transform([new_post])\n",
    "print(new_post_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_raw(v1, v2):\n",
    "    delta = v1 - v2\n",
    "    return sp.linalg.norm(delta.toarray())\n",
    "\n",
    "\n",
    "def best_post(X, new_vec, dis_func):\n",
    "    best_doc = None\n",
    "    best_dis = float('inf')\n",
    "    best_i = None\n",
    "    for i,post in enumerate(posts):\n",
    "        if post == new_post:\n",
    "            continue\n",
    "        post_vec = X.getrow(i)\n",
    "        d = dis_func(post_vec, new_vec)\n",
    "        print(\"I:\",i ,\"POST:\" ,post)\n",
    "        print(\"d:\",d)\n",
    "        if d < best_dis:\n",
    "            best_doc = post\n",
    "            best_i = i\n",
    "    print(\"BEST I:\",best_i ,\"BEST POST:\" ,best_doc)\n",
    "    print(\"best d:\",d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 0 POST: This is a toy post about machine learning. Actually, it contains not much interesting stuff.\nd: 3.1622776601683795\nI: 1 POST: Imaging databases provide storage capabilities.\nd: 1.7320508075688772\nI: 2 POST: Most imaging databases save images permanently.\n\nd: 1.7320508075688772\nI: 3 POST: Imaging databases store data.\nd: 1.4142135623730951\nI: 4 POST: Imaging databases store data. Imaging databases store data. Imaging databases store data.\nd: 5.0990195135927845\nBEST I: 4 BEST POST: Imaging databases store data. Imaging databases store data. Imaging databases store data.\nbest d: 5.0990195135927845\n"
     ]
    }
   ],
   "source": [
    "best_post(x_train, new_post_vec, dis_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先泛化后在求距离\n",
    "def dis_norm(v1, v2):\n",
    "    v1_norm = v1/sp.linalg.norm(v1.toarray())\n",
    "    v2_norm = v2/sp.linalg.norm(v2.toarray())\n",
    "    delta = v1_norm - v2_norm\n",
    "    return sp.linalg.norm(delta.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 0 POST: This is a toy post about machine learning. Actually, it contains not much interesting stuff.\nd: 1.414213562373095\nI: 1 POST: Imaging databases provide storage capabilities.\nd: 0.8573732768944039\nI: 2 POST: Most imaging databases save images permanently.\n\nd: 0.8573732768944039\nI: 3 POST: Imaging databases store data.\nd: 0.7653668647301795\nI: 4 POST: Imaging databases store data. Imaging databases store data. Imaging databases store data.\nd: 0.7653668647301795\nBEST I: 4 BEST POST: Imaging databases store data. Imaging databases store data. Imaging databases store data.\nbest d: 0.7653668647301795\n"
     ]
    }
   ],
   "source": [
    "best_post(x_train, new_post_vec, dis_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将相同词干的词划分为同一个词统计\n",
    "# import nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#k-means示例开始，以20newsgroup数据集为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "all_data = datasets.fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单起见，只用部分新闻组，用categories指定\n",
    "groups = ['comp.graphics', 'comp.os.ms-windows.misc','comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', \n",
    "'comp.windows.x', 'sci.space']\n",
    "train_data = datasets.fetch_20newsgroups(subset='train', categories=groups)\n",
    "test_data = datasets.fetch_20newsgroups(subset='test', categories=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2349\n3529\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data.filenames))\n",
    "print(len(train_data.filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 忽略不合法字符  decode_error='ignore'\n",
    "vectorizer_km = TfidfVectorizer(min_df=10, max_df=.5, stop_words='english', decode_error='ignore')\n",
    "vectorized = vectorizer_km.fit_transform(train_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0, inertia 5975.258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1, inertia 3239.926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  2, inertia 3205.974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  3, inertia 3188.750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  4, inertia 3179.113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  5, inertia 3173.326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  6, inertia 3169.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  7, inertia 3165.893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  8, inertia 3163.532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  9, inertia 3161.955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10, inertia 3160.855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11, inertia 3160.066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, inertia 3159.503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, inertia 3158.896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 14, inertia 3158.242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15, inertia 3157.406\nIteration 16, inertia 3156.724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17, inertia 3156.069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18, inertia 3154.935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19, inertia 3154.300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20, inertia 3154.224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 21, inertia 3154.154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22, inertia 3154.136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 23, inertia 3154.122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 24, inertia 3154.111\nConverged at iteration 24: center shift 0.000000e+00 within tolerance 1.731605e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='random', max_iter=300,\n    n_clusters=50, n_init=1, n_jobs=1, precompute_distances='auto',\n    random_state=3, tol=0.0001, verbose=5)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 50\n",
    "from sklearn.cluster import KMeans\n",
    "# verbose 打印出训练的信息\n",
    "km = KMeans(n_clusters=k, init='random', n_init=1, verbose=5,  random_state=3)\n",
    "km.fit(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用训练的模型开始预测\n",
    "new_post_km = '''\n",
    "Disk drive problems. Hi, I have a problem with my hard disk.\n",
    "After 1 year it is working only sporadically now.\n",
    "I tried to format it, but now it doesn't boot any more.\n",
    "Any ideas? Thanks.\n",
    "'''\n",
    "new_post_km_vec = vectorizer_km.transform([new_post_km])\n",
    "new_post_label = km.predict(new_post_km_vec)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到训练集中与new_post_km属于同一簇的索引\n",
    "# nonzero返回非0的索引\n",
    "similar_indices = (km.labels_ == new_post_label).nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查看索引：\n[66, 69, 139, 157, 167, 201, 213, 214, 225, 228, 233, 308, 323, 324, 351, 354, 359, 370, 384, 392, 428, 446, 453, 463, 479, 531, 533, 563, 580, 581, 618, 619, 676, 689, 714, 731, 779, 806, 807, 808, 905, 935, 939, 944, 961, 964, 976, 987, 1005, 1076, 1221, 1242, 1246, 1266, 1286, 1309, 1313, 1316, 1388, 1389, 1427, 1431, 1481, 1486, 1487, 1512, 1519, 1538, 1548, 1637, 1670, 1716, 1747, 1752, 1769, 1840, 1843, 1852, 1864, 1893, 1986, 1990, 2013, 2085, 2139, 2151, 2235, 2249, 2257, 2270, 2277, 2283, 2306, 2347, 2400, 2412, 2414, 2436, 2443, 2463, 2475, 2493, 2512, 2516, 2518, 2525, 2539, 2565, 2573, 2590, 2600, 2612, 2624, 2651, 2667, 2678, 2705, 2745, 2752, 2791, 2800, 2815, 2842, 2852, 2907, 2947, 2951, 2964, 2993, 3026, 3060, 3065, 3145, 3146, 3160, 3173, 3186, 3192, 3199, 3202, 3214, 3219, 3225, 3285, 3289, 3309, 3321, 3450, 3458]\n维度相同：\n(1, 5651)\n(1, 5651)\n"
     ]
    }
   ],
   "source": [
    "print(\"查看索引：\")\n",
    "print(list(similar_indices))\n",
    "print(\"维度相同：\")\n",
    "print(vectorized[0].shape)\n",
    "print(new_post_km_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similar = []    # 相似文章\n",
    "for i in similar_indices:\n",
    "    dis = sp.linalg.norm((new_post_km_vec - vectorized[i]).toarray())\n",
    "    similar.append((dis, train_data.data[i]))\n",
    "sorted(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.240525206354146, 'From: rtfuhge@immd8.informatik.uni-erlangen.de (Robert Fuhge)\\nSubject: Re: Booting from B drive\\nOrganization: University of Erlangen, csd. AI\\nNNTP-Posting-Host: faui8s3.informatik.uni-erlangen.de\\nLines: 36\\n\\nHi!\\n\\nI think VGA-Copy can do what you need. \\nIf you create a new floppy for your a: drive (that is the 5 1/4\"), turn on\\nthe \"modify\" switch of vga-copy.\\nWhen you boot using this diskette, a message appears:\\n\\nThis is no system disk, you can\\n1) replace disk with another,\\n2) boot from Harddisk or\\n3) switch drives and reboot (that is, a: becomes b:, b: becomes a:)\\nType your choice:\\n\\nWhen you select the third item, you can boot from b: which is now called a: .\\nSeems to work very good, for example booting drdos6 from the installation disks\\nin 3.5\" format was no problem for a friend of mine (I have only a 3.5\" a: drive)\\n\\nHope that helps\\nRobert\\n\\nP.S.: VGA-Copy is shareware, so it\\'s easy to get. Newest Version seems to be 5.0 .\\n\\n-- \\n+-----------------------------------------------------------------------------+\\n|  Robert Fuhge,  Haagstrasse 17,  8520 Erlangen,  Tel. privat: 09131/204103  |\\n|  Email: rtfuhge@cip.informatik.uni-erlangen.de  (demnaechst 91054 Erlangen) |\\n+-----------------------------------------------------------------------------+\\n|  \"Wars are not for to see who is right, but who is left ... \"               |\\n+-----------------------------------------------------------------------------+\\n---\\n+-----------------------------------------------------------------------------+\\n|  Robert Fuhge,  Haagstrasse 17,  8520 Erlangen,  Tel. privat: 09131/204103  |\\n|  Email: rtfuhge@cip.informatik.uni-erlangen.de  (demnaechst 91054 Erlangen) |\\n+-----------------------------------------------------------------------------+\\n|  \"Wars are not for to see who is right, but who is left ... \"               |\\n+-----------------------------------------------------------------------------+\\n')\n"
     ]
    }
   ],
   "source": [
    "print(similar[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
